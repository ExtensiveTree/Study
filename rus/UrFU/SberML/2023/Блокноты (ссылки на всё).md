
# Вводные блокноты 
Блокнот Google Colab с рассмотрением библиотеки numpy <br />
https://colab.research.google.com/drive/1mqh2F1v7QG0O_Bzm9fFIJ53clMbIjkij?usp=sharing <br />
Рассмотрены: <br />
- способы создания массивов numpy 
- особенности индексации и объединения массивов numpy 
- применение функций к массивам numpy 
- маскирование массивов numpy 
- загрузка и сохранение массивов numpy 

Блокнот Google Colab с рассмотрением библиотеки pandas <br />
https://colab.research.google.com/drive/1-EccWJJj_3GvhVrv2kEauYSFG40dbwuW?usp=sharing  <br />
Рассмотрены: <br />
- классы **Series** и **DataFrame** 
- особенности **индексации** Series и DataFrame 
- применение операций к объектам библиотеки pandas 
- агрегирование данных методами **groupby** и **aggregate** 


# Начало работы с данными 

## Загрузка данных в Pandas
Блокнот Google Colab с рассмотрением возможностей библиотеки pandas для анализа табличных данных <br />
https://colab.research.google.com/drive/1Yuj9zNdq3TVplffegiYXO6pQGuV3c10a?usp=sharing <br />
Рассмотрены: 
- функция **read_csv** для считывания данных из файлов 
- методы для получения общей информации и поиска дубликатов 
- функция **to_csv** для сохранения данных в файл 
- логическое индексирование 
- особенности применения метода **sort_values** для сортировки данных 

## Визуализация + Ознакомительный анализ
Ссылка на блокнот «Анализ набора данных Car Moldova» <br />
https://colab.research.google.com/drive/1ZvcWGTGUWbzqhZ1cbNwq4LgztayuScxc?usp=sharing <br />
Рассмотрены: <br />
- анализ числовых признаков с использованием методов **describe**, **groupby**, **corr** 
- анализ категориальных признаков с использованием методов **nunique**, **value_counts**
- визуализация данных с помощью библиотеки **seaborn**
- функции **histplot** для визуализации столбчатых гистограмм  
- функция **pairplot** для визуализации попарных взаимодействий признаков 
- функция **scatterplot** для визуализации диаграмм рассеяния

Ссылка на блокнот «Анализ набора данных Car Moldova. Plotly edition» <br />
https://colab.research.google.com/drive/1565128kvy3eOOtYCHjeTXAZ82GEUBuOQ?usp=sharing <br />
Рассмотрены: <br />
- анализ числовых признаков с использованием методов **describe**, **groupby**, **corr** 
- анализ категориальных признаков с использованием методов **nunique**, **value_counts**
- интерактивная визуализация данных с помощью библиотеки **plotly**

## Предварительная обработка 
Ссылка на Блокнот по предварительной обработке Данных в scikit-learn <br />
https://colab.research.google.com/drive/1q3HsjCPgl9gXwiNxI8OTkpPId8a5QcPD?usp=sharing <br />
Рассмотрены: <br />
- способ загрузки данных из сайта **fetchOpenML** 
- наиболее базовые методы предварительной обработки данных из модуля **scikit-learn.preprocessing**
- стандартизация числовых признаков через **StandardScaler** и степенное преобразование **PowerTransformer**
- простое кодирование категориальных признаков через **LabelEncoder** и **OrdinalEncoder**
- One-hot кодирование через **OneHotEncoder** и сравнение с **get_dummies** от pandas

Ссылка на блокнот «Предварительная обработка набора данных Car Moldova. Pipeline» <br />
https://colab.research.google.com/drive/1es_OrShFiuaeOnlPjX2B1geHDM-XfofM?usp=sharing <br />
Рассмотрены: <br />
- общие принципы работы классов библиотеки **scikit-learn** для предварительной обработки данных (методы **fit** и **transform**) 
- линейная предварительная обработка числовых данных с помощью стандартизации (класс **StandardScaler**) и нормализации (класс **MinMaxScaler**) 
- нелинейная предварительная обработка числовых данных с помощью степенного преобразования (класс **PowerTransformer**) 
- общие принципы создания собственных классов для преобразования данных (наследование от классов **BaseEstimator**, **TransformerMixin**) 
- реализация класса для замены редких значений числовых признаков по квантилям 
- порядковое кодирование категориальных признаков (класс **OrdinalEncoder** ) 
- one-hot кодирование категориальных признаков (класс **OneHotEncoder**) 
- реализация класса для замены редких значений категориальных признаков по частоте встречаемости
- класс **Pipeline**  для систематизации процессов предварительной обработки данных
- класс **ColumnTransformer** для настраивания предварительной обработки отдельных столбцов табличных данных

# Линейная Регрессия
Ссылка на блокнот «Линейная Регрессия для синтетических данных» *своими руками*<br />
https://colab.research.google.com/drive/1sP0qdbA-ecRQrcE9S_JiVsFIapy11VpN?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **numpy** 
- визуализация данных с использованием библиотеки **plotly**
- реализацию функцию для разделения выборки на тренировочную и тестовую
- пошаговую реализацию обучения линейной регрессии методом градиентного спуска, используя функциональный подход
- реализацию обучения линейной регрессии методом градиентного спуска, используя Классы
- возможность усложнения линейной модели через полиномы
- влияние предварительной обработки данных на результаты линейной регрессии
- механизм наследования классов для реализации регуляризации


Ссылка на блокнот «Линейная регрессия для набора данных Car Moldova» <br />
https://colab.research.google.com/drive/1OTWOLQw04mdwepE6ecOnSNXl9_f8bw-E?usp=sharing <br />
Рассмотрены: <br />
- общие принципы работы классов библиотеки **scikit-learn** для моделей машинного обучения (методы **fit** и **predict**) 
- класс **SGDRegressor** от **scikit-learn**- модель линейной регрессии с использованием градиентного спуска ;
- написание собственных функций для анализа, оценки и кросс-валидации моделей машинного обучения 
- способы анализа обученной линейной модели по атрибутам **intercept_** и **coef_** 
- объединение предварительной обработки и модели в единый **Pipeline** 
- обучение модели регрессии с преобразованием целевой переменной (класс **TransformedTargetRegressor**) 
- сохранение и загрузка моделей машинного обучение с использованием библиотеки **joblib**

# Логистическая Регрессия

 
Ссылка на блокнот «Логистическая Регрессия для синтетических данных» *своими руками* <br />
https://colab.research.google.com/drive/1MAliQfLCTMB0pDEGU83hOG9FctK1MuP6?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** 
- механизм наследования классов чтобы не писать всё с нуля
- отрисовку контуров вероятности **contourf** от скучной **matplot-lib**
- метрики классификации 


Ссылка на блокнот «Логистическая регрессия для набора данных Car Moldova» <br />
https://colab.research.google.com/drive/1iEYqqLEXGAo0g-XMljT4GXyn3isDiHb7?usp=sharing <br />
Рассмотрены: <br />
- применение **LabelEncoding** для изменения целевой переменной
- класс **LogisticRegression** от **scikit-learn**- модель логистической регрессии с использованием градиентного спуска;
- написание собственных функций для анализа, оценки и кросс-валидации моделей машинного обучения (взяли в основном из блокнота про линейную регрессию)
- способы анализа обученной линейной модели по атрибутам **intercept_** и **coef_** 
- объединение предварительной обработки и модели в единый **Pipeline** 
- сохранение и загрузка моделей машинного обучение с использованием библиотеки **joblib**

# Метод главных компонент
Ссылка на блокнот «Уменьшение Размерности Методом главных компонент на синтетических (и не очень) данных» *своими руками* <br />
https://colab.research.google.com/drive/1E_dkNiokKxhFICBd6gja63q1IFnLQk1D?usp=sharing<br />
Рассмотрены: <br />
- способы генерирования данных эллипсов 
- реализация метода главных компонент, используя Классы
- скачивание данных с сайта **OpenML**
- анализ результатов метода главных компонент


Ссылка на блокнот «Уменьшение Размерности Методом главных компонент на наборе данных MNIST» <br />
https://colab.research.google.com/drive/1Yovwmm-77_Ce4Md4nL75QjmlOJjOlTkb?usp=sharing<br />
Рассмотрены: <br />
- класс **PCA** от **scikit-learn** - метод главных компонет, что тут сказать  ;
- способ загрузки данных из сайта **OpenML** методом **fetchOpenML** 
- анализ результатов метода главных компонент
- визуализация 3-х мерных диаграмм рассеивания от **plotly**
- использование метода главных компонент для поиска аномалий / шумов в данных

# Кластеризация в целом
## Метод К-Средних
 
Ссылка на блокнот «Кластеризация К-Средних на синтетических данных» *своими руками* <br />
https://colab.research.google.com/drive/1aQWhei4Y4Wthf5VYPDCRS35_3-NdKkk3?usp=sharing<br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** (просто взяли из блокнота про логистическую регрессию)
- функции для вычисления расстояния 
- пошаговая реализация метода к-Средних на функциях и на классах
- **pd.crosstab**, как базовый элемент анализа предсказаний кластеров


## Другие

Ссылка на блокнот «EM-Кластеризация на синтетических данных» <br />
https://colab.research.google.com/drive/1fdQaG4cLn6nVMIJrLIhQ-vCDYyYC6y-Q?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** (просто взяли из блокнота про логистическую регрессию)
- Особенности объекта **GaussianMixture** в **scikit-learn**
- влияние типа матрицы ковариации на результат EM-Кластеризации
- визуализация эллипсов с попощью библиотеки **matplot-lib**

Ссылка на блокнот «Спектральная Кластеризация на синтетических данных» <br />
https://colab.research.google.com/drive/1cmI1IoUAAEVAlYzLirz524fXY4Ao-g65?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** (просто взяли из блокнота про логистическую регрессию)
- Особенности объекта **SpectralClustering** в **scikit-learn**
- анализ матрицы смежности (affinity matrix)

Ссылка на блокнот «Иерархическая кластеризация на синтетических данных» <br />
https://colab.research.google.com/drive/1OlrsU0sgxPxNIg2UNaV4ePoFcQvTLU8H?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** (просто взяли из блокнота про логистическую регрессию)
- Особенности объекта **AgglomerativeClustering** в **scikit-learn**
- визуализация и анализ дендрограммы

Ссылка на блокнот «DBSCAN на синтетических данных» <br />
https://colab.research.google.com/drive/1e7lytJC6kTdcpQOsgpoTy5uSnZlSYsVC?usp=sharing <br />
Рассмотрены: <br />
- способы генерирования данных по определенным "законам" с использованием библиотеки **scikit-learn** (просто взяли из блокнота про логистическую регрессию)
- Особенности объекта **DBSCAN** в **scikit-learn**
- выделение шумовых, граничных и опорных точек


Ссылка на Блокнот «Разная Кластеризация (данные Ирисы)» <br />
https://colab.research.google.com/drive/1OFDiNyAZizh5YR0f3zpLjzG9MDrmsyAz?usp=sharing <br />
Рассмотрены: <br />
- Особенности объекта **KMeans** в **scikit-learn**
- визуализация и анализ коэффициентов силлуэта посчитанных через **silhouette_samples** 
- Особенности объекта **AgglomerativeClustering** в **scikit-learn**
- Особенности объекта **DBSCAN** в **scikit-learn**
- Особенности объекта **SpectralClustering** в **scikit-learn**
- Особенности объекта **GaussianMixture** в **scikit-learn**


# Метрические методы
## к-ближайшие соседи 
Ссылка на Блокнот  Метод k-ближайших соседей в sklearn (Car Moldova) <br />
https://colab.research.google.com/drive/1hNc52qaxO88UQiWLON8IcYb-t1wwohQy?usp=sharing <br />
- Обучение класса **KNeighborsRegressor**
- Поиск лучших гиперпараметров модели с помощью классов **RandomizedSearchCV** и **GridSearchCV**
## t-SNE
Ссылка на блокнот с TSNE + данные MNIST <br />
https://colab.research.google.com/drive/10ZFecLlYXHCXlf4GhBPAEKDiGrmI8Zst?usp=sharing <br />
- класс **TSNE** от **scikit-learn** -


# Разные методы методы
## Метод опорных векторов
Ссылка на Блокнот  Метод опорных векторов для классификации в sklearn (Car Moldova) <br />
https://colab.research.google.com/drive/16yQjVJXTQDasGaMyPI4xHTLd4U66SjHb?usp=sharing <br />
Ссылка на Блокнот  Метод опорных векторов для регрессии в sklearn (Car Moldova) <br />
https://colab.research.google.com/drive/1cgHVcYLTdT4r3AA-rJlBq5mkRPTnSYtq?usp=sharing<br />


# Про бустинг и их друзей
## Деревья Решений 
**«Деревья Решений Car Moldova SE»** (Просто обзор)<br />
https://colab.research.google.com/drive/1gNu1CawE2qXUFJJbMTSFNeEYEWkQunxd?usp=sharing <br /> 
Собственно 
- сами деревья решений в классах **DecisionTreeClassifier**, **DecisionTreeRegressor** 
 - их визуализация  **dtreeviz** <br />

**Деревья решений в sklearn (Car Moldova)** (Подробнее)<br />
https://colab.research.google.com/drive/1-10EgGj8zo3ixvqaxuMk_k11lFFbAcE6?usp=sharing
- Создание класса **TargetEncoder** для кодирования категориальных признаков
- Обучение класса **DecisionTreeRegressor**
- Визуализация моделей деревьев решений с помощью библиотеки **dtreeviz**
- Сохранение модели

## Бустинги и Ансамбли


**Cлучайный леc в sklearn (Car Moldova)** (Подробнее) <br />
https://colab.research.google.com/drive/1tjxeKsT87cn1yypCwFAOokuNkiUJ7YUY?usp=sharing  <br />
- Создание класса **TargetEncoder** для кодирования категориальных признаков
- Обучение класса **RandomForestRegressor**
- Поиск лучших гиперпараметров модели с помощью класса **GridSearchCV**

**Бустинги леc в sklearn (Car Moldova)** (Подробнее) <br />
https://colab.research.google.com/drive/1xHiwBUoHmidolnTCbAz_UIJ6e_DhhWPJ?usp=sharing <br />
- Создание класса **TargetEncoder** для кодирования категориальных признаков
- Обучение класса **AdaBoostRegressor**
- Обучение класса **GradientBoostingRegressor**
- Обучение класса **HistGradientBoostingRegressor**

**CatBoost (Car Moldova)** (Подробнее) <br />
https://colab.research.google.com/drive/1ZsdKlnKcOudjAK2mWBK2zXbhpbA34RkS?usp=sharing <br />
- **CatBoost** 1 <3

**LightGBM (Car Moldova)** (Подробнее) <br />
https://colab.research.google.com/drive/19YvEJwMnIQwAvupk-jSfOnxFh3xCzroq?usp=sharing <br />
- **LightGBM** старается 

**XGBoost (Car Moldova)** (Подробнее) <br />
https://colab.research.google.com/drive/1fO3JYGWVysMPRH6BWQu2GPPVcpNdHV5k?usp=sharing <br />
- **XGBoost** тоже не плох


# Про оптимизацию моделей

**Блокнот про то, как по разному можно делать кросс-валидацию** <br />
https://colab.research.google.com/drive/17hkqdDgoPavQpY3eP-VnLbHVUPIuhIcX?usp=sharing<br />
Визуализация того, как разбиваются данные при разных типах кросс-валидации <br />
-  KFold,    
-  ShuffleSplit,    
-  StratifiedKFold,    
- GroupShuffleSplit,    
- GroupKFold,    
- StratifiedShuffleSplit,    
- StratifiedGroupKFold,
- TimeSeriesSplit,   

**Про отбор гиперпараметров модели** <br />
https://colab.research.google.com/drive/14lOEylbmEQ4ms-UiZ-iOBJdmWSJfpiry?usp=sharing <br />
- Рассмотрение Поиска по сетке **GridSearchCV** и Случайного поиска **RandomizedSearchCV** для отбора гиперпараметров модели
- **Lasso** и **Ridge** Задача регрессии 

**Про Pipeline в scikit-learn	 (подробные комментарии)**<br />
https://colab.research.google.com/drive/1iz_YVPwew25-wTViWGvpYjw7yKAh2P4A?usp=sharing <br />
-  baseline - **LogisticRegression** Задача классификации 
-  **Pipeline**, **ColumnTransformer** конкструируем пайплайны для разных типов данных 
-  **GridSearchCV**  тонкости оптимизации в условиях пайплайнов ( имя__имя_гиперпараметр) 
- проверка гипотезы сработают ли полинамиальные признаки на реальных данных (класс **PolynomialFeatures**)
- сработают ли признаки от метода главных компонент (класс **PCA**)
-  **joblib** для сохранения моделей 

**Небольшой обзор библиотеки Optuna**<br />
https://colab.research.google.com/drive/1eAermb4o3adUgJc6q9AYEKon78vVpNVS?usp=sharing<br />
Оптимизируем тип предварительной обработки, а также гиперпараметри модели <br />
-  baseline **LogisticRegression** Задача классификации 
-  **optuna** - написание функции **objective**
-  визуализация результатов анализа гиперпараметров при поддержке **plotly** (встроено в **optuna** )<br />

**Pipeline is all you need**<br /> 
https://colab.research.google.com/drive/19TMTGc68KR18ZfL3t8JBUs9F8q0cIAPx?usp=sharing<br /> 
ChatGPT-edition <br /> 
-  baseline **SGDRegressor** задача регрессии 
-  **Pipeline**, **ColumnTransformer** конкструируем пайплайны для разных типов данных (и в рамках одного типа данных тоже можем делать разную обработку) 
-  **BaseEstimator**, **TransformerMixin** Пишем кастомные преобразователи данных 
-  **TransformedTargetRegressor** для преобразования целевой переменной тоже 
-  **PredictionErrorDisplay** для визуализации ошибок регрессии
-  **GridSearchCV** для проверки гипотез


# Соревнование по Данным OULAD

**Блокнот в котором показано как работать с соревнованием по регрессии**<br />
https://colab.research.google.com/drive/1tRfbCBl7CzWPo9TIpAXPI6491XOUlSiI?usp=sharing <br />
-  Взаимодействие с **Kaggle API**<br />
-  Работа с **pandas** (**join**)<br />
-  **pipeline** для предварительной обработки данных<br />
-  baseline **Ridge**  линейная регрессия с регуляризацией<br />


**Блокнот в котором показано как работать с соревнованием по классификации**<br />
https://colab.research.google.com/drive/1sojkRfQCYJYmzV-lmP4__cujZL4favCT?usp=sharing<br />
-  Взаимодействие с **Kaggle API**<br />
-  Работа с **pandas** (**join**)<br />
-  **pipeline** для предварительной обработки данных<br />
- baseline **LogisticRegression** логистическая регрессия<br />
